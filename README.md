MusicMood 
Basic Details
Team Name: 404
Team Members
Member 1: Meenakshi A N - College of Engineering Trivandrum
Member 2: Shalini Pulaparambil - College of Engineering Trivandrum
Hosted Project Link
https://github.com/shalini2807-7/MusicMood.git

Project Description
The proposed system is an AI-powered web application that recommends songs based on an uploaded image and the userâ€™s preferred language.
The application allows users to:
Upload an image representing a moment, scene, or emotion.
Select a preferred language for music recommendations.
Receive a curated list of songs that match the mood and context of the image.
The system uses an advanced vision-language model to interpret the image semantically (not just objects, but feelings such as calmness, celebration, travel, nostalgia, etc.).
Based on this interpretation, the application intelligently generates song suggestions and retrieves playable results embedded directly within the website.
The platform combines generative AI, and web development to create an interactive multimedia discovery experience.

The Problem statement
In todayâ€™s digital world, people capture countless images that represent moods, memories, and experiences. However, there is no intuitive system that can transform the emotional or contextual meaning of an image into a personalized music experience.
Existing music platforms rely mainly on manual search, playlists, or listening history, which do not dynamically adapt to visual context. This creates a gap between visual expression and musical discovery.

The Solution
The solution bridges the gap between visual input and music recommendation through an AI-driven pipeline:
ðŸ”¹ Step 1 â€” Image Input
The user uploads an image through a clean and responsive web interface.
ðŸ”¹ Step 2 â€” AI-Based Image Understanding
The AI model analyzes the image to understand:
Scene context (e.g., beach, city, nature)
Emotional tone (e.g., happy, peaceful, energetic)
Activity or atmosphere (e.g., travel, celebration, solitude)
Unlike traditional classification, the model performs semantic interpretation, enabling more human-like understanding.
ðŸ”¹ Step 3 â€” Intelligent Song Suggestion
Using the extracted meaning, the system generates song recommendations that align with:
The detected mood
The environment of the image
The user-selected language
ðŸ”¹ Step 4 â€” Song Retrieval and Display
Each suggested song is searched and displayed as an embedded video player.
ðŸ”¹ Step 5 â€” User Experience
The frontend is designed with a modern, minimal interface to provide:
Smooth interaction
Clear visualization of results
A professional music-discovery feel

Technical Details
Technologies/Components Used
For Software:
Languages used: Python, HTML, CSS
Frameworks used: Flask
Libraries used: google-generativeai, os, flask
Tools used: VS Code, Git

Features
List the key features of your project:
Feature 1: Image-to-Music recommendation using AI
Feature 2: Multilingual song discovery
Feature 3: Context-aware (emotion + environment based) suggestions
Feature 4: Lightweight and scalable web architecture
Feature 5: Real-world application of generative AI in entertainment technology
